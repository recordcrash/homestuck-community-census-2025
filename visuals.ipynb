{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Homestuck Census Data Analysis Notebook\n",
    "\n",
    "A CUDA-accelerated notebook for visualizing and analyzing Homestuck fandom census data.\n",
    "\n",
    "```bash\n",
    "# Required environment\n",
    "uv pip install torch scikit-learn \"umap-learn>=0.5.4,<0.5.7\" \"numba>=0.55,<0.56\" \"llvmlite<0.39\" hdbscan plotly altair wordcloud matplotlib seaborn jupyter notebook ipywidgets widgetsnbextension pandas-profiling\n",
    "```\n"
   ],
   "id": "316d271f53330c1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# from nltk.corpus import stopwords\n",
    "import hdbscan\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "import re\n",
    "import altair as alt\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Settings\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Load data\n",
    "csv_path = 'census_results.csv'\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "# Drop the first five rows (test data)\n",
    "df.drop(index=[0, 1, 2, 3, 4], inplace=True)\n",
    "\n",
    "# Private and useless data (duplicated rows and such)\n",
    "columns_to_drop = [\n",
    "    # Private rows\n",
    "    \"Leave your email here if you want to be contacted about the projects above\",\n",
    "    # Useless for display\n",
    "    \"Are you participating or have you ever participated in one of /r/homestuck's group rereads?\",\n",
    "    \"Would you be interested in giving track art to an official Homestuck album that doesn't have it? (i.e. Beyond Canon Art Anthology)\",\n",
    "    \"Would you be interested in contributing a track to a fanmusic album? (i.e. Land of Fans and Music) \",\n",
    "    \"Would you be interested in contributing track art to a fanmusic album? (i.e. Land of Fans and Music) \",\n",
    "    \"If you have any feedback to improve future surveys, here's your chance!\",\n",
    "    # Removed or changed at some point (only had data for the previous columns)\n",
    "    \"Do you want to order a full list or lazily select your top 3 characters and call it a day?\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [Bard Quest]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [Namco High]\",\n",
    "    \"Favorite major characters\",\n",
    "    \"Select your 3 least favorite characters!.1\",\n",
    "    \"Which 3 characters had the best complete arc?.1\",\n",
    "    \"Which 3 characters had the worst arc?.1\",\n",
    "    \"What's your favorite ship?.1\"\n",
    "]\n",
    "\n",
    "# Drop private columns inplace if they exist\n",
    "df.drop(columns=columns_to_drop, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Remove duplicate/troll answers based on manual check\n",
    "submission_ids_to_drop = [\n",
    "    # Explicitly dropped (trolls, worse duplicates, etc.)\n",
    "    \"R7Z8OK\", \"o4A1AV\", \"rxrxAp\", \"5yzDOM\", \"rxdxeM\", \"4g8YRA\", \"9zWyYK\",\n",
    "    \"rxdxeM\", \"9zWyYK\", \"ed68xo\", \"Xxx9VzY\", \"Nppg5Gb\", \"QKKOxJG\"\n",
    "    # Others from confirmed duplicate IDs\n",
    "    \"Q6DVbX\", \"YLQvAN\", \"0pxY79\", \"XKDajY\", \"E4XOvq\", \"d5Dyvq\", \"2M4j4M\",\n",
    "    \"XKqM7g\", \"E4XoEo\", \"Pa04xB\", \"BPXrgN\", \"GNpoLp\", \"b0MzME\", \"o48L7P\",\n",
    "    \"M9jkD8\", \"M9kN8Y\", \"44XgVPB\", \"jd10Yx\", \"ob6a4zN\", \"Np5V1qN\", \"eqZL7bo\",\n",
    "    \"BO908Y\", \"R706OQ\", \"ZpNKqB\", \"gR4YbD\", \"OpQ4Qg\", \"444KDlk\", \"5BKgEKd\",\n",
    "    \"q2Yjad\", \"11YBAl\"\n",
    "]\n",
    "\n",
    "# Rename columns\n",
    "if \"Submission ID\" in df.columns:\n",
    "    df = df[~df[\"Submission ID\"].isin(submission_ids_to_drop)]\n",
    "    df.rename(columns={\"Submission ID\": \"submission_id\"}, inplace=True)\n",
    "    df.drop(columns=[\"Respondent ID\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "df.sample(5)"
   ],
   "id": "4ab0b23857f80559",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_bar_data(series, top_n=9, other_label=\"Other\"):\n",
    "    \"\"\"\n",
    "    Given a Pandas Series (categorical data), return a DataFrame\n",
    "    with two columns: 'category' and 'count'.\n",
    "    It keeps the top_n categories (by count) and aggregates the\n",
    "    remaining as a single bucket labeled `other_label`.\n",
    "\n",
    "    If `other_label` already exists among the top_n categories,\n",
    "    the new bucket count is added to that existing category.\n",
    "    \"\"\"\n",
    "    counts = series.value_counts(dropna=True)\n",
    "\n",
    "    # If the total number of categories is already <= top_n, no need to bucket\n",
    "    if len(counts) <= top_n:\n",
    "        df_out = counts.reset_index()\n",
    "        df_out.columns = [\"category\", \"count\"]\n",
    "        df_out[\"category\"] = df_out[\"category\"].astype(str)\n",
    "        return df_out\n",
    "\n",
    "    # Otherwise, bucket the extras\n",
    "    top = counts.iloc[:top_n].copy()\n",
    "    rest_sum = counts.iloc[top_n:].sum()\n",
    "\n",
    "    # If 'Other' is already in the top categories, just add to it\n",
    "    if other_label in top.index:\n",
    "        top.loc[other_label] += rest_sum\n",
    "    else:\n",
    "        top[other_label] = rest_sum\n",
    "\n",
    "    df_out = top.reset_index()\n",
    "    df_out.columns = [\"category\", \"count\"]\n",
    "    df_out[\"category\"] = df_out[\"category\"].astype(str)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def apply_fig_aesthetics(figure):\n",
    "    figure.update_layout(\n",
    "        xaxis_title=\"\",            # Remove the X-axis label.\n",
    "        yaxis_title=\"\",\n",
    "        plot_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "        paper_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "        font=dict(family=\"TYPOSTUCK\", color=\"black\", size=40),\n",
    "        title_text=\"\",             # Remove the title from the layout.\n",
    "        margin=dict(l=0, r=0, t=0, b=0)\n",
    "    )\n",
    "\n",
    "# For rows with multiple comma-separated answers, keep only the first answer.\n",
    "def keep_first_choice(text):\n",
    "    parts = text.split(\",\")\n",
    "    return parts[0].strip() if parts else text\n",
    "\n",
    "import re\n",
    "import plotly.express as px\n",
    "\n",
    "def create_bar_chart(df, label, top_n=11, rename_dict=None, output_html=False, output_image=True, sorted_flag=False, show_title=False):\n",
    "    \"\"\"\n",
    "    Create a Plotly Express bar chart from a survey column in a DataFrame, apply cosmetic\n",
    "    settings, optionally sort the categories, and save the outputs (HTML and PNG) using a filename derived from the label.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame containing survey data.\n",
    "        label (str): The column name containing the survey answers.\n",
    "        top_n (int): Maximum number of top categories to include (default is 11).\n",
    "        rename_dict (dict): Optional dictionary for renaming category values.\n",
    "        output_html (bool): If True, the chart is saved as an HTML file.\n",
    "        output_image (bool): If True, the chart is saved as a PNG image.\n",
    "        sorted_flag (bool): If True, sort the categories (assuming numeric values) before plotting.\n",
    "        show_title (bool/str): If true, doesn't hide title, if string, uses that as title\n",
    "\n",
    "    Returns:\n",
    "        fig (plotly.graph_objs._figure.Figure): The generated Plotly figure.\n",
    "\n",
    "    Note:\n",
    "        This function assumes that a helper function named `prepare_bar_data()`\n",
    "        exists and returns a DataFrame with at least \"category\" and \"count\" columns.\n",
    "    \"\"\"\n",
    "    # Normalize the label\n",
    "    normalized_label = re.sub(r\"[^a-zA-Z0-9]\", \"_\", label)\n",
    "\n",
    "    source_series = df[label].astype(\"string\").dropna().apply(keep_first_choice)\n",
    "\n",
    "    # Prepare the aggregated survey data.\n",
    "    survey_data = prepare_bar_data(source_series, top_n=top_n)\n",
    "\n",
    "    # Rename categories if a renaming dictionary is provided.\n",
    "    if rename_dict:\n",
    "        for key, value in rename_dict.items():\n",
    "            survey_data.loc[survey_data[\"category\"] == key, \"category\"] = value\n",
    "\n",
    "    # Convert categories to all uppercase.\n",
    "    survey_data[\"category\"] = survey_data[\"category\"].str.upper()\n",
    "    # Append two spaces to the end of each category (hack for spacing)\n",
    "    survey_data[\"category\"] = survey_data[\"category\"].str.cat([\"  \"] * len(survey_data), sep=\"\")\n",
    "\n",
    "    # Optionally sort the data.\n",
    "    if sorted_flag:\n",
    "        # Try to convert category to a numeric value.\n",
    "        # If conversion fails (e.g., for \">10\"), coerce to NaN and then fill with a fallback value (here, 11)\n",
    "        survey_data[\"sort_val\"] = pd.to_numeric(survey_data[\"category\"], errors=\"coerce\")\n",
    "        survey_data[\"sort_val\"] = survey_data[\"sort_val\"].fillna(11)\n",
    "        # Sort by this numeric value.\n",
    "        survey_data = survey_data.sort_values(by=\"sort_val\")\n",
    "        survey_data = survey_data.drop(columns=\"sort_val\")\n",
    "\n",
    "    # Create the bar chart using Plotly Express.\n",
    "    fig = px.bar(\n",
    "        survey_data,\n",
    "        x=\"count\",\n",
    "        y=\"category\",\n",
    "        color=\"category\",\n",
    "        title=label,  # The title is passed here but later removed from the layout.\n",
    "        template=\"plotly_white\"  # Light mode template.\n",
    "    )\n",
    "\n",
    "    # Configure the bar chart traces.\n",
    "    fig.update_traces(\n",
    "        texttemplate=\"%{x}\",\n",
    "        textposition=\"inside\",\n",
    "        orientation=\"h\",\n",
    "        showlegend=False,\n",
    "        textfont=dict(size=30)  # Increase text size for numbers.\n",
    "    )\n",
    "\n",
    "    apply_fig_aesthetics(fig)\n",
    "\n",
    "    if show_title:\n",
    "        if isinstance(show_title, str):\n",
    "            label = show_title\n",
    "        text_between_brackets = re.findall(r'\\[(.*?)\\]', label)\n",
    "        if text_between_brackets:\n",
    "            label = text_between_brackets[0]\n",
    "        fig.update_layout(\n",
    "            title=label,\n",
    "            margin=dict(l=0, r=0, t=60, b=0)\n",
    "        )\n",
    "\n",
    "    if output_html:\n",
    "        html_filename = f\"graphs/{normalized_label}.html\"\n",
    "        fig.write_html(html_filename, include_plotlyjs=\"cdn\", full_html=False)\n",
    "\n",
    "    if output_image:\n",
    "        image_filename = f\"graphs/{normalized_label}.png\"\n",
    "        fig.write_image(image_filename, width=1500, height=800)\n",
    "    return fig\n"
   ],
   "id": "504270c3705e209d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label = \"Where did you find this survey?\"\n",
    "normalized_label = re.sub(r\"[^a-zA-Z0-9]\", \"_\", label)\n",
    "\n",
    "source_series = df[label].dropna().apply(keep_first_choice)\n",
    "survey_data = prepare_bar_data(source_series, top_n=11)\n",
    "\n",
    "rename_dict = {\n",
    "    \"Homestuck Discord (the one currently doing a reread)\": \"Homestuck Discord\",\n",
    "    \"Twitter-based HS Discord (e.g. Homestuck Anonymous)\": \"Twitter-based HS Discord\",\n",
    "}\n",
    "\n",
    "fig = create_bar_chart(\n",
    "    df,\n",
    "    label=\"Where did you find this survey?\",\n",
    "    top_n=11,\n",
    "    rename_dict=rename_dict\n",
    ")"
   ],
   "id": "b89e151b0500dbb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Combine \"Which gender do you identify the most with?\" and \"Are you transgender?\" into a single virtual column.\n",
    "gender_column = \"Which gender do you identify the most with?\"\n",
    "transgender_column = \"Are you transgender?\"\n",
    "\n",
    "def compute_gender_identity(row):\n",
    "    \"\"\"\n",
    "    Compute a composite gender identity string based on the gender and transgender status in a row.\n",
    "    Returns a string such as \"Trans Male\", \"Cis Female\", \"Trans Nonbinary\", or \"Other\".\n",
    "    If either value is missing, returns pd.NA.\n",
    "    \"\"\"\n",
    "    gender_val_raw = row.get(gender_column, None)\n",
    "    trans_val_raw = row.get(transgender_column, None)\n",
    "\n",
    "    if pd.isna(gender_val_raw) or pd.isna(trans_val_raw):\n",
    "        return pd.NA\n",
    "\n",
    "    # Clean and standardize the inputs.\n",
    "    gender_val_raw = gender_val_raw.strip()\n",
    "    trans_val_raw = trans_val_raw.strip()\n",
    "\n",
    "    # Standardize the gender value.\n",
    "    if gender_val_raw.lower() == \"male\":\n",
    "        gender_standard = \"Male\"\n",
    "    elif gender_val_raw.lower() == \"female\":\n",
    "        gender_standard = \"Female\"\n",
    "    elif gender_val_raw.lower() == \"nonbinary\":\n",
    "        gender_standard = \"Nonbinary\"\n",
    "    else:\n",
    "        gender_standard = \"Other\"\n",
    "\n",
    "    # Determine the transgender status.\n",
    "    if trans_val_raw.lower() == \"yes\":\n",
    "        trans_prefix = \"Trans\"\n",
    "    elif trans_val_raw.lower() == \"no\":\n",
    "        trans_prefix = \"Cis\"\n",
    "    else:\n",
    "        trans_prefix = \"\"\n",
    "\n",
    "    # Combine the values.\n",
    "    if trans_prefix:\n",
    "        return f\"{trans_prefix} {gender_standard}\"\n",
    "    else:\n",
    "        return gender_standard\n",
    "\n",
    "if gender_column in df.columns and transgender_column in df.columns:\n",
    "    df[\"gender_identity\"] = df.apply(compute_gender_identity, axis=1)\n",
    "\n",
    "fig = create_bar_chart(\n",
    "    df,\n",
    "    label=\"gender_identity\",\n",
    "    top_n=11,\n",
    "    rename_dict=rename_dict\n",
    ")"
   ],
   "id": "f190a6c2e72d6098",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Define the column to plot.\n",
    "transgender_column = \"Are you transgender?\"\n",
    "\n",
    "# Filter out missing responses.\n",
    "trans_series = df[transgender_column].dropna()\n",
    "\n",
    "# Map the responses: \"Yes\" becomes \"Trans\" and \"No\" becomes \"Cis\".\n",
    "trans_series = trans_series.replace({\"Yes\": \"Trans\", \"No\": \"Cis\"})\n",
    "\n",
    "# Compute counts for each mapped response.\n",
    "trans_counts = trans_series.value_counts().reset_index()\n",
    "trans_counts.columns = [\"response\", \"count\"]\n",
    "\n",
    "# Create the pie chart using Plotly Express.\n",
    "fig_pie = px.pie(\n",
    "    trans_counts,\n",
    "    names=\"response\",\n",
    "    values=\"count\",\n",
    "    title=\"Trans vs Cis\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Update the pie chart trace so the labels appear inside the slices with both label and percentage.\n",
    "fig_pie.update_traces(\n",
    "    textposition='inside',\n",
    "    textinfo='label+percent',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Apply common figure aesthetics.\n",
    "apply_fig_aesthetics(fig_pie)\n",
    "\n",
    "# Display the pie chart.\n",
    "fig_pie.write_image(\"graphs/trans_pie.png\", width=400, height=400)"
   ],
   "id": "83e7da22e39e73d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label = \"Which orientation do you identify the most with?\"\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label=label,\n",
    "    top_n=11,\n",
    "    rename_dict={}\n",
    ")"
   ],
   "id": "4636c272041ce170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label = \"What's your relationship status?\"\n",
    "\n",
    "source_series = df[label]\n",
    "survey_data = prepare_bar_data(source_series, top_n=11)\n",
    "\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label=label,\n",
    "    top_n=11,\n",
    "    rename_dict={}\n",
    ")"
   ],
   "id": "7227d4ef4ee670cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label = \"What's your relationship status?\"\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label=label,\n",
    "    top_n=11,\n",
    "    rename_dict={}\n",
    ")"
   ],
   "id": "7aa4bd877b8b9547",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label = \"Which ethnicity or race/s do you identify the most with?\\n\"\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label=label,\n",
    "    top_n=11,\n",
    "    rename_dict={}\n",
    ")"
   ],
   "id": "7f0584c336a3014f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from upsetplot import UpSet, from_memberships\n",
    "import seaborn as sns\n",
    "\n",
    "def reduce_categories(df, col, top_n=9, other_label=\"Other\"):\n",
    "    \"\"\"\n",
    "    For the given column in df, keep only the top_n most frequent categories.\n",
    "    All other values are replaced with the other_label.\n",
    "    The column is then converted to a categorical dtype.\n",
    "    \"\"\"\n",
    "    # Get value frequencies, excluding NaN (we will leave NaNs untouched)\n",
    "    freq = df[col].value_counts(dropna=True)\n",
    "    # Get the top_n categories (if there are fewer than top_n, they will all be kept)\n",
    "    top_categories = freq.index[:top_n].tolist()\n",
    "\n",
    "    # Replace values not in the top list with other_label, leave NaN as is\n",
    "    df[col] = df[col].apply(lambda x: x if pd.isna(x) or x in top_categories else other_label)\n",
    "    return df[col]\n",
    "\n",
    "def create_upset_plot(\n",
    "        df,\n",
    "        label=\"Which ethnicity or race/s do you identify the most with?\\n\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates an UpSet plot for the ethnicity/race question that:\n",
    "      - Uses a transparent background and black TYPOSTUCK text\n",
    "      - Colors the set-size bars in different colors (using a colormap)\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The survey DataFrame.\n",
    "        label (str): The column name for the ethnicity/race question.\n",
    "    \"\"\"\n",
    "    # 1. Parse the multi-choice responses.\n",
    "    #    Split comma-separated strings and strip extra whitespace.\n",
    "    eth_series = df[label].copy().dropna().apply(lambda x: [cat.strip() for cat in x.split(\",\")])\n",
    "\n",
    "    # 4. Build the upset data.\n",
    "    upset_data = from_memberships(eth_series).copy()  # explicitly make a copy\n",
    "    if not upset_data.index.is_unique:\n",
    "        upset_data = upset_data.groupby(level=list(range(upset_data.index.nlevels))).sum().copy()\n",
    "\n",
    "    # 5. Set matplotlib aesthetics: TYPOSTUCK font\n",
    "    plt.rcParams[\"font.family\"] = \"TYPOSTUCK\"\n",
    "\n",
    "    # 6. Build and plot the UpSet object.\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    upset = UpSet(upset_data, show_counts=True, sort_by=\"cardinality\", facecolor=\"green\")\n",
    "\n",
    "    upset.plot(fig=fig)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"graphs/ethnicity_upset.png\", dpi=500)\n",
    "\n",
    "label = \"Which ethnicity or race/s do you identify the most with?\\n\"\n",
    "df[label] = reduce_categories(df.copy(), label, top_n=13, other_label=\"Other\")\n",
    "# create_upset_plot(df, label=label)\n"
   ],
   "id": "cefad869e4df1b0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label = \"Are you employed?\"\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label=label,\n",
    "    top_n=11,\n",
    "    rename_dict={}\n",
    ")"
   ],
   "id": "80f43271facf673d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from upsetplot import UpSet, from_indicators\n",
    "\n",
    "col_system   = \"\\\"I'm belong to/I am/I have...\\\" (I'm part of a System (DID/MPD/etc))\"\n",
    "col_adhd     = \"\\\"I'm belong to/I am/I have...\\\" (I have ADHD/attention issues)\"\n",
    "col_autistic = \"\\\"I'm belong to/I am/I have...\\\" (I'm autistic/on the spectrum)\"\n",
    "col_neurodiv = \"\\\"I'm belong to/I am/I have...\\\" (I'm neurodivergent in another way (PTSD, OCD, BPD, etc))\"\n",
    "col_furry    = \"\\\"I'm belong to/I am/I have...\\\" (I'm a furry)\"\n",
    "\n",
    "# Create a new DataFrame with just those columns and rename them.\n",
    "selected = df[[col_system, col_adhd, col_autistic, col_neurodiv, col_furry]].copy()\n",
    "selected = selected.rename(columns={\n",
    "    col_system:   \"system\",\n",
    "    col_adhd:     \"adhd\",\n",
    "    col_autistic: \"autistic\",\n",
    "    col_neurodiv: \"neurodiv\",\n",
    "    col_furry:    \"furry\"\n",
    "})\n",
    "\n",
    "# Convert the columns to booleans.\n",
    "for col in [\"system\", \"adhd\", \"autistic\", \"neurodiv\", \"furry\"]:\n",
    "    selected[col] = selected[col].astype(bool)\n",
    "\n",
    "# Create upset data from the boolean indicator DataFrame.\n",
    "upset_data = from_indicators(selected)\n",
    "\n",
    "# Set matplotlib aesthetics for a transparent background and black TYPOSTUCK text.\n",
    "plt.rcParams[\"font.family\"] = \"TYPOSTUCK\"\n",
    "\n",
    "# Build and display the UpSet plot.\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "upset = UpSet(upset_data, show_counts=True, sort_by=\"cardinality\", facecolor=\"green\", subset_size=\"count\")\n",
    "upset.plot(fig=fig)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/identity_upset.png\", dpi=500)\n",
    "# plt.show()"
   ],
   "id": "6022dfea4586ae7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "econ_col = \"Economic scale (1 Left to 5 Right)\"\n",
    "soc_col  = \"Social scale (1 Authoritarian to 5 Libertarian)\"\n",
    "\n",
    "# Create a new DataFrame with only the two columns (drop rows where either is missing)\n",
    "compass = df[[econ_col, soc_col]].dropna()\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot the scatter points (with low alpha so the density shows up clearly)\n",
    "sns.scatterplot(data=compass, x=econ_col, y=soc_col, color=\"blue\", alpha=0.2, s=20)\n",
    "\n",
    "# Overlay a filled 2D kernel density estimation\n",
    "sns.kdeplot(\n",
    "    data=compass,\n",
    "    x=econ_col,\n",
    "    y=soc_col,\n",
    "    fill=True,\n",
    "    cmap=\"binary\",\n",
    "    alpha=1.0,\n",
    "    thresh=0.05\n",
    ")\n",
    "\n",
    "# Draw dotted lines at the midpoint (3) for both axes to delineate quadrants.\n",
    "plt.axhline(3, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "plt.axvline(3, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "# Set axis labels and title\n",
    "plt.xlabel(\"\", fontsize=12, fontname=\"TYPOSTUCK\", color=\"black\")\n",
    "plt.ylabel(\"\", fontsize=12, fontname=\"TYPOSTUCK\", color=\"black\")\n",
    "\n",
    "plt.gca().set_ylim(6, 0)\n",
    "plt.gca().set_xlim(0, 6)\n",
    "plt.gca().patch.set_alpha(0.0)\n",
    "plt.gcf().patch.set_alpha(0.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/compass_density.png\", dpi=500)\n",
    "# plt.show()\n"
   ],
   "id": "8c34dddc3bd9a8e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # required for 3D plotting\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Data Preparation\n",
    "# -------------------------------\n",
    "# Assume these are the columns you are using:\n",
    "econ_col = \"Economic scale (1 Left to 5 Right)\"\n",
    "soc_col  = \"Social scale (1 Authoritarian to 5 Libertarian)\"\n",
    "\n",
    "# Extract data and drop rows with missing values.\n",
    "compass = df[[econ_col, soc_col]].dropna()\n",
    "x = compass[econ_col].values\n",
    "y = compass[soc_col].values\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Compute the 2D Density\n",
    "# -------------------------------\n",
    "# Stack the x and y arrays\n",
    "values = np.vstack([x, y])\n",
    "kde = gaussian_kde(values)\n",
    "\n",
    "# Create a regular grid over the range [1, 5] for both axes.\n",
    "x_grid = np.linspace(1, 5, 100)\n",
    "y_grid = np.linspace(1, 5, 100)\n",
    "xx, yy = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "# Evaluate the KDE on the grid.\n",
    "grid_positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "density = np.reshape(kde(grid_positions), xx.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Load the Texture Image and Rotate It\n",
    "# -------------------------------\n",
    "img = mpimg.imread(\"texturemap.png\")\n",
    "# Convert to float format (so that the RGBA values are in [0,1]) if necessary.\n",
    "if img.dtype.kind != 'f':\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "# If the image is RGB (3 channels) add an alpha channel.\n",
    "if img.shape[2] == 3:\n",
    "    alpha_channel = np.ones((img.shape[0], img.shape[1], 1))\n",
    "    img = np.dstack([img, alpha_channel])\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Compute Texture Mapping Coordinates\n",
    "# -------------------------------\n",
    "# Since our x and y ranges are [1,5] (Economic and Social scales),\n",
    "# we want to map these values to [0,1] for texture coordinates.\n",
    "# Here we do NOT invert the axes.\n",
    "u = (xx - 1) / (5 - 1)   # Economic axis mapping: (x - 1) / 4.\n",
    "v = (yy - 1) / (5 - 1)   # Social axis mapping: (y - 1) / 4.\n",
    "# Clip u and v into [0,1] to avoid indexing errors.\n",
    "u_clip = np.clip(u, 0, 1)\n",
    "v_clip = np.clip(v, 0, 1)\n",
    "\n",
    "# Determine the image dimensions.\n",
    "nrows, ncols, _ = img.shape\n",
    "# Map (u,v) coordinates to the pixel indices of the rotated image.\n",
    "row_idx = (v_clip * (nrows - 1)).astype(np.int32)\n",
    "col_idx = (u_clip * (ncols - 1)).astype(np.int32)\n",
    "# Use these indices to sample the image and get RGBA facecolors.\n",
    "facecolors = img[row_idx, col_idx, :]\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Plot the 3D Density Surface with the Texture Overlay\n",
    "# -------------------------------\n",
    "fig = plt.figure(figsize=(10, 8), facecolor=\"none\")\n",
    "ax = fig.add_subplot(111, projection='3d', facecolor=\"none\")\n",
    "fig.patch.set_alpha(0.0)\n",
    "# Set the axis pane colors to transparent.\n",
    "ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "ax.grid(False)\n",
    "\n",
    "# Plot the surface. We disable shading so that our facecolors (the texture) display unmodified.\n",
    "surf = ax.plot_surface(xx, yy, density, rstride=1, cstride=1, facecolors=facecolors,\n",
    "                       edgecolor='none', shade=False, alpha=0.8)\n",
    "\n",
    "# Set the labels and title.\n",
    "ax.set_xlabel(\"Economic (1 = Left, 5 = Right)\", fontname=\"TYPOSTUCK\", color=\"black\")\n",
    "ax.set_ylabel(\"Social (1 = Authoritarian, 5 = Libertarian)\", fontname=\"TYPOSTUCK\", color=\"black\")\n",
    "ax.set_zlabel(\"Density\", fontname=\"TYPOSTUCK\", color=\"black\")\n",
    "ax.set_title(\"3D Density Plot with Texture Overlay\", fontname=\"TYPOSTUCK\", color=\"black\")\n",
    "\n",
    "# Optionally, add a color bar.\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/compass_3d_density.png\", dpi=500)\n",
    "# plt.show()"
   ],
   "id": "abd70594d8e95fb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "fav_col = \"Select your 3 favorite characters!\"\n",
    "least_col = \"Select your 3 least favorite characters!\"\n",
    "\n",
    "# Helper function to get counts\n",
    "def count_characters(df, column):\n",
    "    all_chars = []\n",
    "    for entry in df[column].dropna():\n",
    "        chars = [c.strip() for c in entry.split(\",\") if c.strip()]\n",
    "        all_chars.extend(chars)\n",
    "    return Counter(all_chars)\n",
    "\n",
    "# Count frequencies\n",
    "fav_counts = count_characters(df, fav_col)\n",
    "least_counts = count_characters(df, least_col)\n",
    "\n",
    "# Union of all character names\n",
    "all_chars = set(fav_counts.keys()).union(set(least_counts.keys()))\n",
    "\n",
    "# Compute controversy metrics\n",
    "rows = []\n",
    "for char in all_chars:\n",
    "    fav = fav_counts.get(char, 0)\n",
    "    least = least_counts.get(char, 0)\n",
    "    total = fav + least\n",
    "    nci = (2 * min(fav, least)) / total if total > 0 else 0\n",
    "    rows.append({\n",
    "        \"character\": char,\n",
    "        \"favorite_count\": fav,\n",
    "        \"least_favorite_count\": least,\n",
    "        \"normalized_controversy_index\": round(nci, 3),\n",
    "        \"total_mentions\": total\n",
    "    })\n",
    "\n",
    "# Sort by NCI first, then total mentions\n",
    "controversy_df = pd.DataFrame(rows).sort_values(\n",
    "    by=[\"normalized_controversy_index\", \"total_mentions\"],\n",
    "    ascending=[False, False]\n",
    ")\n",
    "\n",
    "controversy_df"
   ],
   "id": "2b9279752ae13b70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "orig_area = [\n",
    "  {\"orig_area\": \"STEM\", \"count\": \"1737\"},\n",
    "  {\"orig_area\": \"Arts\", \"count\": \"1303\"},\n",
    "  {\"orig_area\": \"Retail\", \"count\": \"653\"},\n",
    "  {\"orig_area\": \"Humanities\", \"count\": \"369\"},\n",
    "  {\"orig_area\": \"Social Sciences\", \"count\": \"300\"},\n",
    "  {\"orig_area\": \"Skilled Trades\", \"count\": \"290\"},\n",
    "  {\"orig_area\": \"Undecided\", \"count\": \"279\"},\n",
    "  {\"orig_area\": \"Health\", \"count\": \"279\"},\n",
    "  {\"orig_area\": \"Education\", \"count\": \"258\"},\n",
    "  {\"orig_area\": \"Business & Finance\", \"count\": \"229\"},\n",
    "  {\"orig_area\": \"Public Service\", \"count\": \"209\"},\n",
    "  {\"orig_area\": \"Other\", \"count\": \"104\"},\n",
    "  {\"orig_area\": \"Communications\", \"count\": \"77\"},\n",
    "  {\"orig_area\": \"Law\", \"count\": \"70\"}\n",
    "]\n",
    "\n",
    "df_orig = pd.DataFrame(orig_area)\n",
    "\n",
    "df_orig[\"count\"] = df_orig[\"count\"].astype(int)\n",
    "\n",
    "responses = []\n",
    "for _, row in df_orig.iterrows():\n",
    "    responses.extend([row[\"orig_area\"]] * row[\"count\"])\n",
    "\n",
    "df_responses = pd.DataFrame({\"orig_area\": responses})\n",
    "\n",
    "create_bar_chart(\n",
    "    df_responses,\n",
    "    label=\"orig_area\",  # Column name containing our responses.\n",
    "    top_n=11,           # For example, to show top 11 categories.\n",
    "    rename_dict={}\n",
    ")"
   ],
   "id": "ab0dee04396d507f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "\n",
    "# Columns (dates in string format)\n",
    "last_read_col = \"Approximately when did you last \\\"read\\\" the comic?\"\n",
    "join_col = \"Approximately when did you join the Homestuck fandom?\"\n",
    "\n",
    "# Convert the date columns to datetime.\n",
    "df['join_date'] = pd.to_datetime(df[join_col], errors='coerce')\n",
    "df['last_read_date'] = pd.to_datetime(df[last_read_col], errors='coerce')\n",
    "\n",
    "# Define a complete date range.\n",
    "full_range = pd.date_range(start='2009-04-13', end='2025-04-01')\n",
    "\n",
    "# Compute daily counts for each column.\n",
    "join_counts = df['join_date'].value_counts().sort_index()\n",
    "last_read_counts = df['last_read_date'].value_counts().sort_index()\n",
    "\n",
    "# Reindex counts over the full date range (filling missing dates with 0).\n",
    "join_series = join_counts.reindex(full_range, fill_value=0)\n",
    "last_read_series = last_read_counts.reindex(full_range, fill_value=0)\n",
    "\n",
    "# Smooth the counts with a 30-day rolling average.\n",
    "join_smooth = join_series.rolling(window=30, min_periods=1).mean()\n",
    "last_read_smooth = last_read_series.rolling(window=30, min_periods=1).mean()\n",
    "\n",
    "# Add an offset to handle zeros when using log scale.\n",
    "join_smooth_offset = join_smooth + 1\n",
    "last_read_smooth_offset = last_read_smooth + 1\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot join events.\n",
    "plt.plot(full_range, join_smooth_offset, label='Joined Fandom', color='blue')\n",
    "plt.fill_between(full_range, join_smooth_offset, color='blue', alpha=0.3)\n",
    "\n",
    "# Plot last read events.\n",
    "plt.plot(full_range, last_read_smooth_offset, label='Last Read Comic', color='red')\n",
    "plt.fill_between(full_range, last_read_smooth_offset, color='red', alpha=0.3)\n",
    "\n",
    "# Set logarithmic y-axis.\n",
    "plt.yscale('log')\n",
    "\n",
    "# Draw a horizontal line at the offset value (1) for reference.\n",
    "plt.axhline(1, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xlabel(\"Date\", fontsize=12, fontname=\"TYPOSTUCK\", color=\"black\")\n",
    "plt.ylabel(\"Number of Responses (30-day avg.)\", fontsize=12, fontname=\"TYPOSTUCK\", color=\"black\")\n",
    "plt.title(\"Timeline of Joining vs. Last Reading (Smoothed)\", fontsize=14, fontname=\"TYPOSTUCK\", color=\"black\")\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# --- Annotate Peaks ---\n",
    "# Define our date range of interest.\n",
    "lower_bound = pd.Timestamp(\"2010-01-01\")\n",
    "upper_bound = pd.Timestamp(\"2024-01-01\")\n",
    "\n",
    "# Create masks for the valid date range.\n",
    "mask_join = (full_range >= lower_bound) & (full_range < upper_bound)\n",
    "mask_read = (full_range >= lower_bound) & (full_range < upper_bound)\n",
    "\n",
    "# Restrict unsmoothed series to the valid range.\n",
    "join_series_valid = join_series[mask_join]\n",
    "last_read_series_valid = last_read_series[mask_read]\n",
    "\n",
    "# Find peaks on the raw (unsmoothed) data.\n",
    "peaks_join, _ = find_peaks(join_series_valid.values, prominence=0.5)\n",
    "peaks_read, _ = find_peaks(last_read_series_valid.values, prominence=0.5)\n",
    "\n",
    "# Retrieve corresponding dates from the valid indices.\n",
    "valid_join_dates = join_series_valid.index\n",
    "valid_read_dates = last_read_series_valid.index\n",
    "\n",
    "# Build DataFrames of peaks for each series.\n",
    "df_peaks_join = pd.DataFrame({\n",
    "    \"date\": valid_join_dates[peaks_join],\n",
    "    \"value\": join_series_valid.values[peaks_join],\n",
    "    \"type\": \"join\"\n",
    "})\n",
    "df_peaks_read = pd.DataFrame({\n",
    "    \"date\": valid_read_dates[peaks_read],\n",
    "    \"value\": last_read_series_valid.values[peaks_read],\n",
    "    \"type\": \"read\"\n",
    "})\n",
    "\n",
    "# Select top 5 joined peaks (by raw count) and top 10 read peaks.\n",
    "df_top_join = df_peaks_join.sort_values(by=\"value\", ascending=False).head(5)\n",
    "df_top_read = df_peaks_read.sort_values(by=\"value\", ascending=False).head(10)\n",
    "\n",
    "# Combine the two sets.\n",
    "df_top_peaks = pd.concat([df_top_join, df_top_read], ignore_index=True)\n",
    "# If duplicates exist for the same date, drop them.\n",
    "df_top_peaks = df_top_peaks.drop_duplicates(subset=[\"date\"])\n",
    "\n",
    "# To annotate on the plotted (smoothed+offset) curve, define a helper.\n",
    "def get_annotated_value(date, typ):\n",
    "    # For join events, use join_smooth_offset; for read events, last_read_smooth_offset.\n",
    "    if typ == \"join\":\n",
    "        return join_smooth_offset.loc[date]\n",
    "    else:\n",
    "        return last_read_smooth_offset.loc[date]\n",
    "\n",
    "# Annotate each selected peak.\n",
    "# Instead of multiplying the y-value, we use an offset in \"offset points\" to ensure the\n",
    "# annotation appears clearly above the peak.\n",
    "for _, row in df_top_peaks.iterrows():\n",
    "    date = row[\"date\"]\n",
    "    typ = row[\"type\"]\n",
    "    y_val = get_annotated_value(date, typ)\n",
    "    date_str = date.strftime(\"%Y-%m-%d\")\n",
    "    plt.annotate(date_str,\n",
    "                 xy=(date, y_val),\n",
    "                 xytext=(0,20),          # 20 points above the arrow tip\n",
    "                 textcoords=\"offset points\",\n",
    "                 arrowprops=dict(arrowstyle=\"->\", color='black'),\n",
    "                 fontsize=10, fontname=\"TYPOSTUCK\", color=\"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/timeline_density_smoothed.png\", dpi=500, transparent=True)\n",
    "# plt.show()\n"
   ],
   "id": "4577fdeeb3191c43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the join_date column is in datetime format.\n",
    "df['join_date'] = pd.to_datetime(df[\"Approximately when did you join the Homestuck fandom?\"], errors='coerce')\n",
    "\n",
    "# Drop any rows where join_date is NaT (if you want to ignore them).\n",
    "df_valid = df.dropna(subset=['join_date']).copy()\n",
    "\n",
    "# Extract the year from the join_date.\n",
    "df_valid['join_year'] = df_valid['join_date'].dt.year\n",
    "\n",
    "# Count the number of respondents per join year.\n",
    "year_counts = df_valid['join_year'].value_counts().sort_index()\n",
    "\n",
    "# Calculate the total number of valid join entries.\n",
    "total = year_counts.sum()\n",
    "\n",
    "# Compute percentages and round to (say) 1 decimal place.\n",
    "percentages = (year_counts / total * 100).round(1)\n",
    "\n",
    "# Create a new DataFrame for output.\n",
    "result_df = pd.DataFrame({\n",
    "    'Fandom Join Year': year_counts.index,\n",
    "    'Count': year_counts.values,\n",
    "    'Percentage': percentages.values\n",
    "})\n",
    "\n",
    "result_df = result_df.sort_values(by='Fandom Join Year')\n",
    "\n",
    "# Display the resulting table.\n",
    "print(result_df.to_string(index=False))\n"
   ],
   "id": "893a4e13622363da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "col_how_many_times = \"How many times have you \\\"read\\\" Homestuck?\"\n",
    "col_hardcore = \"On a scale of 0 (accidentally started this survey) to 10 (has put thousands of hours into the comic/fandom) how hardcore a fan of Homestuck are you?\"\n",
    "\n",
    "df_howmany = df.copy()\n",
    "# floor value to int\n",
    "# df_howmany[col_how_many_times] = df_howmany[col_how_many_times].dropna().apply(lambda x: x if x <= 10 else 11)\n",
    "# df_howmany[col_how_many_times] = df_howmany[col_how_many_times].dropna().astype(\"int\").astype(\"string\")\n",
    "# df_howmany[col_hardcore] = df_howmany[col_hardcore].dropna().astype(\"int\").astype(\"string\")\n",
    "\n",
    "numeric_rename_dict = {\"1.0\": \"1\", \"2.0\": \"2\", \"3.0\": \"3\", \"4.0\": \"4\", \"5.0\": \"5\", \"6.0\": \"6\", \"7.0\": \"7\", \"8.0\": \"8\", \"9.0\": \"9\", \"10.0\": \"10\"}\n",
    "create_bar_chart(\n",
    "    df_howmany,\n",
    "    label=col_how_many_times,  # Column name containing our responses.\n",
    "    top_n=9,           # For example, to show top 11 categories.\n",
    "    rename_dict=numeric_rename_dict,\n",
    "    sorted_flag=True\n",
    ")"
   ],
   "id": "c415354b34790a3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "create_bar_chart(\n",
    "    df_howmany,\n",
    "    label=col_hardcore,  # Column name containing our responses.\n",
    "    top_n=10,           # For example, to show top 11 categories.\n",
    "    rename_dict=numeric_rename_dict,\n",
    "    sorted_flag=True\n",
    ")"
   ],
   "id": "d9d07623c3ce8664",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "learn_of_hs_col = \"How did you first learn of Homestuck?\"\n",
    "\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label = learn_of_hs_col,  # Column name containing our responses.\n",
    "    top_n = 11,  # For example, to show top 11 categories.\n",
    "    rename_dict = {}\n",
    ")"
   ],
   "id": "ccf9eeafa9bb2a80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Define the desired order as a list.\n",
    "order_list = [\n",
    "    \"Act 1\", \"Act 2\", \"Act 3\", \"Intermission 1\", \"Act 4\",\n",
    "    \"Act 5 Act 1 (Hivebent)\", \"Act 5 Act 2\", \"Intermission 2\",\n",
    "    \"A6A1\", \"A6I1\", \"A6A2\", \"A6I2\", \"A6A3\", \"A6I3 (Meenah)\", \"A6A4\", \"A6I4\", \"A6A5 (Trickster)\", \"A6I5\",\n",
    "    \"A6A6A1\", \"A6A6I1\", \"A6A6A2\", \"A6A6I2\", \"A6A6A3\", \"A6A6I3\", \"A6A6A4\", \"A6A6I4 (Retcon)\", \"A6A6A5\", \"A6A6I5 (Lilypad)\",\n",
    "    \"A6A6A6 (Collide)\", \"Act 7\"\n",
    "]\n",
    "\n",
    "groups = {\n",
    "    \"A1-A5\": {\"Act 1\", \"Act 2\", \"Act 3\", \"Intermission 1\", \"Act 4\", \"Act 5 Act 1 (Hivebent)\", \"Act 5 Act 2\", \"Intermission 2\"},\n",
    "    \"A6A1-5\": {\"A6A1\", \"A6I1\", \"A6A2\", \"A6I2\", \"A6A3\", \"A6I3 (Meenah)\", \"A6A4\", \"A6I4\", \"A6A5 (Trickster)\", \"A6I5\"},\n",
    "    \"A6A6 (All)\": {\"A6A6A1\", \"A6A6I1\", \"A6A6A2\", \"A6A6I2\", \"A6A6A3\", \"A6A6I3\", \"A6A6A4\", \"A6A6I4 (Retcon)\", \"A6A6A5\", \"A6A6I5 (Lilypad)\", \"A6A6A6 (Collide)\"},\n",
    "}\n",
    "\n",
    "groups[\"A6 (All)\"] = groups[\"A6A1-5\"].union(groups[\"A6A6 (All)\"])\n",
    "\n",
    "# Define your color rules.\n",
    "def get_colors(act):\n",
    "    # early acts\n",
    "    if act in {\"Act 1\", \"Act 2\", \"Act 3\", \"Act 4\", \"Intermission 1\", \"A1-A5\"}:\n",
    "        if act == \"Intermission 1\":\n",
    "            return (\"green\", \"green\")\n",
    "        else:\n",
    "            return (\"white\", \"black\")\n",
    "    elif act == \"Act 5 Act 1 (Hivebent)\":\n",
    "        return (\"blue\", \"blue\")\n",
    "    elif act == \"Act 5 Act 2\":\n",
    "        return (\"red\", \"red\")\n",
    "    elif act == \"Intermission 2\":\n",
    "        return (\"green\", \"green\")\n",
    "    elif act in {\"A6 (All)\", \"A6A1-5\", \"A6A6 (All)\"}:\n",
    "        return (\"green\", \"green\")\n",
    "    elif act in {\"A6A1\", \"A6A2\", \"A6A3\", \"A6A4\", \"A6A5 (Trickster)\",\n",
    "                 \"A6I1\", \"A6I2\", \"A6I3 (Meenah)\", \"A6I4\", \"A6I5\"}:\n",
    "        # Early Act 6: if the act contains an \"I\", use light green; otherwise white.\n",
    "        if \"I\" in act:\n",
    "            return (\"#90EE90\", \"#90EE90\")\n",
    "        else:\n",
    "            return (\"white\", \"black\")\n",
    "    elif act in {\"A6A6I1\", \"A6A6I2\", \"A6A6I3\", \"A6A6I4 (Retcon)\", \"A6A6I5 (Lilypad)\",\n",
    "                 \"A6A6A1\", \"A6A6A2\", \"A6A6A3\", \"A6A6A4\", \"A6A6A5\"}:\n",
    "        # Late Act 6: if the act contains an \"I\", use white; otherwise dark green.\n",
    "        if \"I\" in act:\n",
    "            return (\"white\", \"black\")\n",
    "        else:\n",
    "            return (\"#006400\", \"#006400\")\n",
    "    elif act in {\"A6A6A6 (Collide)\", \"Act 7\"}:\n",
    "        return (\"black\", \"black\")\n",
    "    else:\n",
    "        return (\"gray\", \"gray\")\n",
    "\n",
    "# Create an aggregated DataFrame from the survey responses.\n",
    "# Assume your DataFrame is df and has a column \"What is your favorite Act?\"\n",
    "act_counts = df[\"What is your favorite Act?\"].value_counts().reset_index()\n",
    "act_counts.columns = [\"act\", \"count\"]\n",
    "\n",
    "# Convert count to integer (if necessary).\n",
    "act_counts[\"count\"] = act_counts[\"count\"].astype(int)\n",
    "\n",
    "# Add fill and stroke color columns.\n",
    "act_counts[\"fill\"] = act_counts[\"act\"].apply(lambda x: get_colors(x)[0])\n",
    "act_counts[\"stroke\"] = act_counts[\"act\"].apply(lambda x: get_colors(x)[1])\n",
    "\n",
    "# Create an ordering column based on the desired order_list.\n",
    "def get_order(act):\n",
    "    try:\n",
    "        # Lower index means earlier appearance.\n",
    "        return order_list.index(act)\n",
    "    except ValueError:\n",
    "        # If not found in the list, assign a high value.\n",
    "        return 999\n",
    "\n",
    "act_counts[\"order\"] = act_counts[\"act\"].apply(get_order)\n",
    "\n",
    "# Calculate the aggregated counts for each group defined in 'groups'\n",
    "group_rows = []\n",
    "# Determine a starting order value that is larger than any individual act.\n",
    "group_order_start = act_counts[\"order\"].max() + 1\n",
    "for i, (group_name, act_set) in enumerate(groups.items()):\n",
    "    # Sum the counts of the acts that are in the current group.\n",
    "    group_count = act_counts[act_counts[\"act\"].isin(act_set)][\"count\"].sum()\n",
    "    # Create a new row for this group.\n",
    "    group_rows.append({\n",
    "        \"act\": group_name,\n",
    "        \"count\": group_count,\n",
    "        \"fill\": get_colors(group_name)[0],\n",
    "        \"stroke\": get_colors(group_name)[1],\n",
    "        \"order\": group_order_start + i\n",
    "    })\n",
    "# Create a DataFrame from the group rows and append to act_counts.\n",
    "group_df = pd.DataFrame(group_rows)\n",
    "act_counts = pd.concat([act_counts, group_df], ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by the custom order.\n",
    "act_counts = act_counts.sort_values(\"order\")\n",
    "\n",
    "# Create a vertical bar chart with the x-axis carrying the labels and y-axis the count.\n",
    "fig = px.bar(\n",
    "    act_counts,\n",
    "    x=\"act\",\n",
    "    y=\"count\",\n",
    "    text=\"count\",\n",
    "    title=\"\"\n",
    ")\n",
    "\n",
    "# Update layout for transparent background and custom fonts.\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"\",            # Remove X-axis title.\n",
    "    yaxis_title=\"\",\n",
    "    plot_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "    paper_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "    font=dict(family=\"TYPOSTUCK\", color=\"black\", size=25),\n",
    "    title_text=\"\",             # Remove main title from layout.\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    showlegend=False          # Remove the legend.\n",
    ")\n",
    "\n",
    "# Update marker settings to use the per-bar colors.\n",
    "fig.update_traces(\n",
    "    marker=dict(\n",
    "        color=list(act_counts[\"fill\"]),\n",
    "        line=dict(color=list(act_counts[\"stroke\"]), width=2)\n",
    "    ),\n",
    "    texttemplate=\"%{text}\"\n",
    ")\n",
    "\n",
    "# Use a normalized label for file names.\n",
    "normalized_label = re.sub(r\"[^a-zA-Z0-9]\", \"_\", \"What is your favorite Act?\")\n",
    "# html_filename = f\"{normalized_label}.html\"\n",
    "# fig.write_html(html_filename, include_plotlyjs=\"cdn\", full_html=False)\n",
    "\n",
    "image_filename = f\"graphs/{normalized_label}.png\"\n",
    "fig.write_image(image_filename, width=1500, height=800)\n",
    "\n",
    "# fig.show()\n"
   ],
   "id": "857c31d6ca780957",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Ensure the age column is numeric.\n",
    "df[\"How old are you?\"] = pd.to_numeric(df[\"How old are you?\"], errors='coerce')\n",
    "\n",
    "# Remove rows with missing age values.\n",
    "df_age = df.dropna(subset=[\"How old are you?\"]).copy()\n",
    "\n",
    "# Define a function to bucket the age.\n",
    "def bucket_age(age):\n",
    "    if age < 10:\n",
    "        return \"<10\"\n",
    "    elif age <= 42:\n",
    "        return str(int(age))\n",
    "    else:\n",
    "        return \">42\"\n",
    "\n",
    "# Create a new column \"age_bucket\" using the bucketing function.\n",
    "df_age[\"age_bucket\"] = df_age[\"How old are you?\"].apply(bucket_age)\n",
    "\n",
    "# Aggregate the data: count the number of respondents per age bucket.\n",
    "age_counts = df_age[\"age_bucket\"].value_counts().reset_index()\n",
    "age_counts.columns = [\"age_bucket\", \"count\"]\n",
    "age_counts[\"count\"] = age_counts[\"count\"].astype(int)\n",
    "\n",
    "# Define a helper function to get the ordering value for each bucket.\n",
    "def bucket_order(bucket):\n",
    "    if bucket == \"<10\":\n",
    "        return 0\n",
    "    elif bucket == \">42\":\n",
    "        return 43\n",
    "    else:\n",
    "        try:\n",
    "            return int(bucket)  # for numeric buckets (10 through 41)\n",
    "        except:\n",
    "            return 999\n",
    "\n",
    "age_counts[\"order\"] = age_counts[\"age_bucket\"].apply(bucket_order)\n",
    "\n",
    "# Sort the DataFrame by our custom order.\n",
    "age_counts = age_counts.sort_values(\"order\")\n",
    "\n",
    "# Create a vertical bar chart using Plotly Express.\n",
    "fig = px.bar(\n",
    "    age_counts,\n",
    "    x=\"age_bucket\",\n",
    "    y=\"count\",\n",
    "    text=\"count\",\n",
    "    title=\"Age Distribution\",\n",
    "    color=\"age_bucket\"\n",
    ")\n",
    "\n",
    "# Update the layout to use a transparent background and TYPOSTUCK font.\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Age Bucket\",\n",
    "    yaxis_title=\"Count\",\n",
    "    plot_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "    paper_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "    font=dict(family=\"TYPOSTUCK\", color=\"black\", size=25),\n",
    "    title_text=\"\",\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "apply_fig_aesthetics(fig)\n",
    "\n",
    "# For file names, normalize the label.\n",
    "normalized_label = re.sub(r\"[^a-zA-Z0-9]\", \"_\", \"How old are you?\")\n",
    "# html_filename = f\"{normalized_label}.html\"\n",
    "# fig.write_html(html_filename, include_plotlyjs=\"cdn\", full_html=False)\n",
    "\n",
    "image_filename = f\"graphs/{normalized_label}.png\"\n",
    "fig.write_image(image_filename, width=1500, height=800)\n",
    "\n",
    "# fig.show()\n"
   ],
   "id": "536ae2944727e395",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Helper function to extract the country name from a response.\n",
    "def extract_country(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    if \"Flag\" in text:\n",
    "        after = text.split(\"Flag\", 1)[1]\n",
    "        country = after.splitlines()[0].strip()\n",
    "    else:\n",
    "        country = text.strip()\n",
    "    if country == \"United Kingdom of Great Britain and Northern Ireland\":\n",
    "        return \"United Kingdom\"\n",
    "    return country\n",
    "\n",
    "# Process the \"Respondent's country\" column.\n",
    "df[\"Respondent_country\"] = df[\"Respondent's country\"].apply(extract_country)\n",
    "df_valid = df.dropna(subset=[\"Respondent_country\"]).copy()\n",
    "\n",
    "# Aggregate counts per country.\n",
    "country_counts = df_valid[\"Respondent_country\"].value_counts().reset_index()\n",
    "country_counts.columns = [\"country\", \"count\"]\n",
    "\n",
    "# Compute percentages.\n",
    "total = country_counts[\"count\"].sum()\n",
    "country_counts[\"percent\"] = (country_counts[\"count\"] / total * 100).round(1)\n",
    "\n",
    "# For a log scale effect, compute the log10 of the percent.\n",
    "country_counts[\"log_percent\"] = np.log10(country_counts[\"percent\"])\n",
    "\n",
    "# Define tick values and labels for the colorbar.\n",
    "ticks = np.linspace(country_counts[\"log_percent\"].min(), country_counts[\"log_percent\"].max(), 5)\n",
    "tick_labels = [f\"{10**t:.1f}%\" for t in ticks]\n",
    "\n",
    "# Create a Plotly Express choropleth using the log-transformed percentage.\n",
    "fig = px.choropleth(\n",
    "    country_counts,\n",
    "    locations=\"country\",\n",
    "    locationmode=\"country names\",\n",
    "    color=\"log_percent\",\n",
    "    color_continuous_scale=\"Greens\",\n",
    "    hover_data=[\"count\", \"percent\"],\n",
    "    title=\"\"\n",
    ")\n",
    "\n",
    "# Update layout: use transparent backgrounds and custom fonts.\n",
    "fig.update_layout(\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(family=\"TYPOSTUCK\", color=\"black\"),\n",
    "    showlegend=False,\n",
    "    coloraxis_colorbar=dict(\n",
    "        title=\"Percentage\",\n",
    "        tickvals=ticks,\n",
    "        ticktext=tick_labels\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update geo settings to achieve a light-mode look.\n",
    "fig.update_geos(\n",
    "    bgcolor=\"rgba(0,0,0,0)\",        # transparent background for the map container\n",
    "    lakecolor=\"rgba(255,255,255,1)\",  # lakes as white\n",
    "    landcolor=\"rgba(240,240,240,1)\",  # light gray for land\n",
    "    showcountries=True,\n",
    "    countrycolor=\"rgba(200,200,200,1)\"  # light borders for countries\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "apply_fig_aesthetics(fig)\n",
    "\n",
    "# Save the figure as HTML and as a PNG image (1500 x 800).\n",
    "normalized_label = re.sub(r\"[^a-zA-Z0-9]\", \"_\", \"Respondent's country\")\n",
    "# html_filename = f\"{normalized_label}.html\"\n",
    "# fig.write_html(html_filename, include_plotlyjs=\"cdn\", full_html=False)\n",
    "\n",
    "image_filename = f\"graphs/{normalized_label}.png\"\n",
    "fig.write_image(image_filename, width=1500, height=800)\n"
   ],
   "id": "b325568884adb0dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "country_counts",
   "id": "1733d3543440c64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "col_platforms = \"What platform did you last \\\"read\\\" Homestuck on (including active rereads)?\"\n",
    "\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label = col_platforms,  # Column name containing our responses.\n",
    "    top_n = 4,  # For example, to show top 11 categories.\n",
    "    rename_dict = {}\n",
    ")\n"
   ],
   "id": "894cbaf3a4c34fd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[\"Which of these Homestuck franchiselets have you perused? [Homestuck]\"].value_counts()",
   "id": "5765e55102d5f982",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "franchise_columns = [\n",
    "    \"Which of these Homestuck franchiselets have you perused? [Homestuck]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [HS Epilogues]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [SBaHJ]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [Problem Sleuth]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [Jailbreak]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [Paradox Space]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [HSBC/HS^2]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [Hiveswap Act 1]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [Hiveswap Act 2]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [Friendsim]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [Pesterquest]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [Skaianet Systems]\",\n",
    "    \"Which of these Homestuck franchiselets have you perused? [Psycholonials]\"\n",
    "]\n",
    "\n",
    "# Define the response categories (as they appear in responses)\n",
    "response_categories = [\"Finished\", \"Started\", \"Dropped\", \"Didn't start\", \"Never heard of\"]\n",
    "\n",
    "# Define a function to extract the area name from the column header.\n",
    "def extract_area(col_name):\n",
    "    m = re.search(r\"\\[(.+?)\\]\", col_name)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    return col_name\n",
    "\n",
    "# Create a list to hold aggregated dictionaries.\n",
    "agg_list = []\n",
    "\n",
    "# Loop through each franchiselet column.\n",
    "for col in franchise_columns:\n",
    "    # Get the raw counts via value_counts().\n",
    "    counts = df[col].dropna().value_counts()\n",
    "    # Build a dict with keys for each response category.\n",
    "    data = {cat: counts.get(cat, 0) for cat in response_categories}\n",
    "    data[\"franchiselet\"] = extract_area(col)\n",
    "    agg_list.append(data)\n",
    "\n",
    "# Create a DataFrame where each row is a franchiselet and columns are response counts.\n",
    "df_franchise = pd.DataFrame(agg_list)\n",
    "# --- Reshape Data to Long Format ---\n",
    "# Each row will represent one response category for a given franchiselet.\n",
    "df_long = df_franchise.melt(\n",
    "    id_vars=[\"franchiselet\"],\n",
    "    value_vars=[\"Finished\", \"Started\", \"Dropped\", \"Didn't start\", \"Never heard of\"],\n",
    "    var_name=\"Response\",\n",
    "    value_name=\"Count\"\n",
    ")\n",
    "\n",
    "# --- Define Colors for Each Response Category ---\n",
    "color_map = {\n",
    "    \"Dropped\": \"red\",\n",
    "    \"Started\": \"#90EE90\",       # Light green\n",
    "    \"Finished\": \"#006400\",      # Dark green\n",
    "    \"Didn't start\": \"lightgrey\",\n",
    "    \"Never heard of\": \"white\"\n",
    "}\n",
    "\n",
    "# --- Create a Stacked Bar Chart ---\n",
    "fig = px.bar(\n",
    "    df_long,\n",
    "    x=\"franchiselet\",\n",
    "    y=\"Count\",\n",
    "    color=\"Response\",\n",
    "    text=\"Count\",\n",
    "    title=\"\",\n",
    "    color_discrete_map=color_map,\n",
    "    barmode=\"stack\"  # Stacked mode\n",
    ")\n",
    "\n",
    "# Update the layout for a transparent background and custom fonts.\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(family=\"TYPOSTUCK\", color=\"black\", size=25),\n",
    "    title_text=\"\",\n",
    "    xaxis_title=\"\",            # Remove the X-axis label.\n",
    "    yaxis_title=\"\",\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickangle=45)\n",
    "\n",
    "# --- Save the Figure ---\n",
    "normalized_label = re.sub(r\"[^a-zA-Z0-9]\", \"_\", \"Which_of_these_Homestuck_franchiselets_have_you_perused\")\n",
    "# html_filename = f\"{normalized_label}.html\"\n",
    "# fig.write_html(html_filename, include_plotlyjs=\"cdn\", full_html=False)\n",
    "\n",
    "image_filename = f\"graphs/{normalized_label}.png\"\n",
    "fig.write_image(image_filename, width=1500, height=800)\n"
   ],
   "id": "e07efcd4fe861ad7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "\n",
    "# List of rating question columns in desired order.\n",
    "rating_columns = [\n",
    "    \"How do you rate Homestuck overall?\",\n",
    "    \"How do you rate Homestuck's ending?\",\n",
    "    \"How do you rate the Homestuck Epilogues?\",\n",
    "    \"How do you rate Problem Sleuth?\",\n",
    "    \"How do you rate Paradox Space?\",\n",
    "    \"How do you rate Homestuck: Beyond Canon/Homestuck^2?\",\n",
    "    \"How do you rate Hiveswap Act 1?\",\n",
    "    \"How do you rate Hiveswap Act 2?\",\n",
    "    \"How do you rate Hiveswap Friendsim?\",\n",
    "    \"How do you rate Pesterquest?\",\n",
    "    \"How do you rate Psycholonials?\"\n",
    "]\n",
    "\n",
    "# Create a copy of the DataFrame and ensure numeric conversion.\n",
    "df_ratings = df.copy()\n",
    "for col in rating_columns:\n",
    "    df_ratings[col] = pd.to_numeric(df_ratings[col], errors=\"coerce\")\n",
    "# Drop rows that are missing values in all rating columns.\n",
    "df_ratings = df_ratings.dropna(subset=rating_columns)\n",
    "\n",
    "# Melt the DataFrame to long format.\n",
    "df_long = df_ratings.melt(\n",
    "    value_vars=rating_columns,\n",
    "    var_name=\"Question\",\n",
    "    value_name=\"Rating\"\n",
    ")\n",
    "\n",
    "# Define a function to simplify question text.\n",
    "def simplify_question(q):\n",
    "    if q == \"How do you rate Homestuck: Beyond Canon/Homestuck^2?\":\n",
    "        return \"HSBC/HS^2\"\n",
    "    # Remove the \"How do you rate\" prefix and any trailing punctuation.\n",
    "    q = re.sub(r\"^How do you rate the\\s*\", \"\", q)\n",
    "    q = re.sub(r\"^How do you rate\\s*\", \"\", q)\n",
    "    q = re.sub(r\"\\?$\", \"\", q)\n",
    "    return q.strip()\n",
    "\n",
    "df_long[\"Question_Simple\"] = df_long[\"Question\"].apply(simplify_question)\n",
    "\n",
    "# Compute the average rating per simplified question.\n",
    "avg_per_question = df_long.groupby(\"Question_Simple\")[\"Rating\"].mean().round(1)\n",
    "\n",
    "# Create a box plot (horizontal, i.e. box plot on x, categories on y).\n",
    "fig = px.box(\n",
    "    df_long,\n",
    "    x=\"Rating\",\n",
    "    y=\"Question_Simple\",\n",
    "    orientation=\"h\",\n",
    "    title=\"\",\n",
    "    points=False,  # Do not show all discrete data points\n",
    "    color=\"Question_Simple\",\n",
    ")\n",
    "\n",
    "# Update layout for transparent background and custom fonts.\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"\",\n",
    "    yaxis_title=\"\",\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(family=\"TYPOSTUCK\", color=\"black\", size=30),\n",
    "    margin=dict(l=100, r=50, t=50, b=50),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Overlay the average ratings as scatter markers.\n",
    "# Create a new trace for averages.\n",
    "avg_trace = go.Scatter(\n",
    "    x=list(avg_per_question.values),\n",
    "    y=list(avg_per_question.index),\n",
    "    mode=\"text\",\n",
    "    text=avg_per_question,\n",
    "    name=\"Average Rating\"\n",
    ")\n",
    "fig.add_trace(avg_trace)\n",
    "\n",
    "# Update colorbar etc. Here we don't have a colorbar for the box plot.\n",
    "# Set the category ordering on the y-axis according to the order of rating_columns.\n",
    "ordered_questions = [simplify_question(q) for q in rating_columns]\n",
    "fig.update_yaxes(categoryorder=\"array\", categoryarray=ordered_questions)\n",
    "\n",
    "# Save the figure as HTML and PNG (1500x800), then display.\n",
    "normalized_label = re.sub(r\"[^a-zA-Z0-9]\", \"_\", \"Ratings_of_Homestuck_and_Related\")\n",
    "# html_filename = f\"{normalized_label}.html\"\n",
    "# fig.write_html(html_filename, include_plotlyjs=\"cdn\", full_html=False)\n",
    "\n",
    "apply_fig_aesthetics(fig)\n",
    "\n",
    "image_filename = f\"graphs/{normalized_label}.png\"\n",
    "fig.write_image(image_filename, width=1500, height=800)\n"
   ],
   "id": "c83397073553b6a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Define the column to plot.\n",
    "lunar_column = \"What is your Lunar Sway?\"\n",
    "\n",
    "# Filter out missing responses.\n",
    "lunar_series = df[lunar_column].dropna()\n",
    "\n",
    "# Compute counts for each mapped response.\n",
    "lunar_counts = lunar_series.value_counts().reset_index()\n",
    "lunar_counts.columns = [\"response\", \"count\"]\n",
    "\n",
    "# Prospit should be gold, Derse should be purple\n",
    "color_map = {\"Prospit\": \"gold\", \"Derse\": \"purple\"}\n",
    "\n",
    "# Create the pie chart using Plotly Express.\n",
    "fig_pie = px.pie(\n",
    "    lunar_counts,\n",
    "    names=\"response\",\n",
    "    values=\"count\",\n",
    "    title=\"\",\n",
    "    color=\"response\",\n",
    "    color_discrete_map=color_map,\n",
    ")\n",
    "\n",
    "\n",
    "# Apply common figure aesthetics.\n",
    "apply_fig_aesthetics(fig_pie)\n",
    "\n",
    "# Update the pie chart trace so the labels appear inside the slices with both label and percentage.\n",
    "fig_pie.update_traces(\n",
    "    textposition='inside',\n",
    "    textinfo='label+percent',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Display the pie chart.\n",
    "fig_pie.write_image(\"graphs/moon_pie.png\", width=400, height=400)"
   ],
   "id": "559835a61f6a1ec1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# List of fanwork types (the text inside the square brackets in your columns).\n",
    "fanwork_types = [\n",
    "    \"Fanart\", \"Fanmusic\", \"Fanvideos\", \"Fanfiction/adventures\",\n",
    "    \"Cosplay\", \"Theories\", \"Roleplay\", \"Fangames/mods\", \"Other (i.e. wikis)\"\n",
    "]\n",
    "\n",
    "# Rename dictionary for long fanwork labels.\n",
    "rename_dict = {\n",
    "    \"Fanfiction/adventures\": \"Fanfiction\",\n",
    "    \"Fangames/mods\": \"Fangames\",\n",
    "    \"Other (i.e. wikis)\": \"Wiki/other\"\n",
    "}\n",
    "\n",
    "# We'll loop over the fanwork types to aggregate data.\n",
    "agg_list = []\n",
    "\n",
    "for fanwork in fanwork_types:\n",
    "    col_label = f\"How often have you created fanwork for the Homestuck fandom, and in which ways? [{fanwork}]\"\n",
    "    # Get value counts for the column.\n",
    "    counts = df[col_label].dropna().value_counts().reset_index()\n",
    "    counts.columns = [\"response\", \"count\"]\n",
    "    # Add a column for fanwork type.\n",
    "    counts[\"Fanwork_Type\"] = fanwork\n",
    "    agg_list.append(counts)\n",
    "\n",
    "# Concatenate all fanwork aggregated data.\n",
    "df_fanwork = pd.concat(agg_list, ignore_index=True)\n",
    "\n",
    "# Apply renaming for fanwork types.\n",
    "df_fanwork[\"Fanwork_Type\"] = df_fanwork[\"Fanwork_Type\"].replace(rename_dict)\n",
    "\n",
    "# Create a faceted bar chart using Plotly Express.\n",
    "fig = px.bar(\n",
    "    df_fanwork,\n",
    "    x=\"response\",\n",
    "    y=\"count\",\n",
    "    color=\"response\",\n",
    "    text=\"count\",\n",
    "    facet_col=\"Fanwork_Type\",\n",
    "    category_orders={\"Fanwork_Type\": sorted(df_fanwork[\"Fanwork_Type\"].unique(), key=lambda x: fanwork_types.index(x) if x in fanwork_types else 999)},\n",
    "    barmode=\"stack\",\n",
    "    title=\"\"  # Remove title.\n",
    ")\n",
    "\n",
    "# Remove any automatic facet prefixes.\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1].strip()))\n",
    "\n",
    "# Update layout: transparent backgrounds, custom TYPOSTUCK font.\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "    paper_bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "    font=dict(family=\"TYPOSTUCK\", color=\"black\", size=20),\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "    showlegend=True  # We want a legend here.\n",
    ")\n",
    "\n",
    "# Rotate x-axis tick labels (response labels) so they are diagonal.\n",
    "fig.update_xaxes(tickangle=45)\n",
    "\n",
    "# Save the figure as HTML and PNG with dimensions 1500 x 800.\n",
    "normalized_label = re.sub(r\"[^a-zA-Z0-9]\", \"_\", \"Fanwork_Creation\")\n",
    "# html_filename = f\"{normalized_label}.html\"\n",
    "# fig.write_html(html_filename, include_plotlyjs=\"cdn\", full_html=False)\n",
    "\n",
    "image_filename = f\"graphs/{normalized_label}.png\"\n",
    "fig.write_image(image_filename, width=1500, height=800)"
   ],
   "id": "27ddec85f29c1081",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "def deduplicate_response(text):\n",
    "    \"\"\"\n",
    "    Lowercase the text, remove punctuation, split into words, deduplicate,\n",
    "    and return a space-separated string of unique words.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    unique_words = set(words)\n",
    "    return \" \".join(unique_words)\n",
    "\n",
    "# Combine the two free text columns.\n",
    "old_texts = df[\"What's your favorite \\\"old\\\" fanwork?\"].dropna().astype(str).tolist()\n",
    "current_texts = df[\"What's your favorite \\\"current\\\" fanwork?\"].dropna().astype(str).tolist()\n",
    "\n",
    "# Process each response to remove duplicate words.\n",
    "old_texts = [deduplicate_response(resp) for resp in old_texts]\n",
    "current_texts = [deduplicate_response(resp) for resp in current_texts]\n",
    "\n",
    "combined_text = \" \".join(current_texts + old_texts)\n",
    "\n",
    "# Create a custom set of stopwords.\n",
    "custom_stopwords = set(STOPWORDS)\n",
    "custom_stopwords.update([\n",
    "    \"fanwork\", \"work\", \"favorite\", \"old\", \"current\", \"homestuck\",\n",
    "    \"the\", \"and\", \"of\", \"in\", \"a\", \"to\", \"https\", \"goes\", \"idk\",\n",
    "    \"dunno\", \"know\", \"s\", \"stuff\", \"fanfic\", \"fanfiction\",\n",
    "    \"fic\", \"anything\", \"really\", \"yet\", \"probably\", \"none\",\n",
    "    \"youtube\", \"youtu\", \"archiveofourown\", \"org\", \"ao3\", \"called\",\n",
    "])\n",
    "\n",
    "# Create the WordCloud object.\n",
    "wc = WordCloud(\n",
    "    width=1500,\n",
    "    height=800,\n",
    "    background_color=\"white\",   # Light background.\n",
    "    stopwords=custom_stopwords,\n",
    "    colormap=\"viridis\",\n",
    "    font_path=\"fontstuck-extended.ttf\",\n",
    "    collocations=True\n",
    ").generate(combined_text)\n",
    "\n",
    "# Plot the word cloud.\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(\"graphs/fanwork_wordcloud.png\", format=\"png\", dpi=300, transparent=True)\n",
    "plt.show()\n"
   ],
   "id": "b392cfc4d32c4b92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "quest_bedding_col = \"Would you buy quest bed bedding?\"\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label = quest_bedding_col,  # Column name containing our responses.\n",
    "    top_n = 4,  # For example, to show top 11 categories.\n",
    "    rename_dict = {},\n",
    "    show_title=\"Quest Bedding\"\n",
    ")"
   ],
   "id": "89ca0a3e441bc6ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "wizard_col = \"Would you buy a physical SBURB guide/lorebook à la Wizardology? \"\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label = wizard_col,  # Column name containing our responses.\n",
    "    top_n = 4,  # For example, to show top 11 categories.\n",
    "    rename_dict = {},\n",
    "    show_title=\"SBURB guide\"\n",
    ")"
   ],
   "id": "1c154709f8eadb8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "streaming_col = \"Do you want more official Homestuck musicians to individually add all their Homestuck songs to streaming, à la Bowmanstuck?\"\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label = streaming_col,  # Column name containing our responses.\n",
    "    top_n = 4,  # For example, to show top 11 categories.\n",
    "    rename_dict = {},\n",
    "    show_title=\"Homestuck Music on Streaming\"\n",
    ")"
   ],
   "id": "f38a1e6f9f5ab520",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "streaming_col = \"Would you buy a physical copy of the Homestuck Soundtrack? \"\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label = streaming_col,  # Column name containing our responses.\n",
    "    top_n = 3,  # For example, to show top 11 categories.\n",
    "    rename_dict = {},\n",
    "    show_title=\"Physical Soundtrack\"\n",
    ")"
   ],
   "id": "ce006dbb70d70fb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "paradox_col = \"Would you buy a new physical book of official non-canon Homestuck side comics à la Paradox Space?\"\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label = paradox_col,  # Column name containing our responses.\n",
    "    top_n = 4,  # For example, to show top 11 categories.\n",
    "    rename_dict = {},\n",
    "    show_title=\"Paradox Space-esque book\"\n",
    ")"
   ],
   "id": "8920949451378af6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "books_cont_col = \"Would you buy a continuation of the Homestuck books from Cascade onwards?\"\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label = books_cont_col,  # Column name containing our responses.\n",
    "    top_n = 4,  # For example, to show top 11 categories.\n",
    "    rename_dict = {},\n",
    "    show_title=\"More Homestuck books\"\n",
    ")"
   ],
   "id": "9fcac268d283c432",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "new_albums_col = \"Would you buy/stream new official Homestuck music albums?\"\n",
    "create_bar_chart(\n",
    "    df,\n",
    "    label = new_albums_col,  # Column name containing our responses.\n",
    "    top_n = 4,  # For example, to show top 11 categories.\n",
    "    rename_dict = {},\n",
    "    show_title=\"More Homestuck albums\"\n",
    ")"
   ],
   "id": "1ba0315faadfd7a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "col = \"Share your merch wishlist beyond the above\"\n",
    "\n",
    "# Drop missing responses and convert them to strings.\n",
    "responses = df[col].dropna().astype(str).tolist()\n",
    "\n",
    "def deduplicate_response(text):\n",
    "    \"\"\"\n",
    "    Process a single response: lower-case it, remove punctuation,\n",
    "    split into words, and then return a string of the unique words (order is not preserved).\n",
    "    \"\"\"\n",
    "    # Lower-case the text.\n",
    "    text = text.lower()\n",
    "    # Remove punctuation (using a regex that matches alphanumeric words).\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    # Use a set to deduplicate.\n",
    "    unique_words = set(words)\n",
    "    # Return as a space-separated string.\n",
    "    return \" \".join(unique_words)\n",
    "\n",
    "# Process each response so that repeated words in the same response are only counted once.\n",
    "processed_responses = [deduplicate_response(resp) for resp in responses]\n",
    "\n",
    "# Combine the processed responses into a single aggregated text.\n",
    "aggregated_text = \" \".join(processed_responses)\n",
    "\n",
    "# Create a custom set of stopwords.\n",
    "custom_stopwords = set(STOPWORDS)\n",
    "# I can't use something more advanced because so much of Homestuck is\n",
    "# common words, like \"god\" for god tier or \"kind\" for kind abstrata\n",
    "custom_stopwords.update([\n",
    "    \"merch\", \"wishlist\", \"the\", \"and\", \"of\", \"in\", \"a\", \"to\", \"for\",\n",
    "    \"any\", \"things\", \"i\", \"you\", \"it\", \"on\", \"with\", \"or\", \"this\", \"that\",\n",
    "    \"my\", \"just\", \"more\", \"like\", \"but\", \"is\", \"are\", \"was\", \"were\",\n",
    "    \"https\", \"http\", \"com\", \"org\", \"www\", \"official\", \"please\", \"buy\",\n",
    "    \"anything\", \"homestuck\", \"much\", \"im\", \"stuff\", \"zendaya\", \"love\",\n",
    "    \"know\", \"think\", \"though\", \"will\", \"fucking\", \"put\", \"really\",\n",
    "    \"literally\", \"kill\", \"now\", \"etc\", \"whatever\", \"dont\", \"never\",\n",
    "    \"still\", \"shit\", \"way\", \"nice\", \"funny\", \"cute\", \"release\",\n",
    "    \"m\", \"oh\", \"wish\", \"miss\", \"thing\", \"give\", \"lot\", \"people\",\n",
    "    \"little\", \"especially\", \"new\", \"actual\", \"version\", \"many\",\n",
    "    \"look\", \"actually\", \"alway\", \"even\", \"wanted\", \"every\",\n",
    "    \"good\", \"real\", \"pretty\", \"long\", \"well\", \"sell\", \"honestly\",\n",
    "    \"come\", \"don\", \"available\", \"make\", \"man\", \"got\", \"used\",\n",
    "    \"tbh\", \"take\", \"u\", \"something\", \"related\", \"themed\", \"ass\",\n",
    "    \"ve\", \"us\", \"find\", \"two\", \"bought\", \"sick\", \"d\", \"wanna\",\n",
    "    \"able\", \"stupid\", \"beg\", \"idea\", \"better\", \"great\", \"id\",\n",
    "    \"always\", \"begging\", \"bring\", \"cool\", \"maybe\", \"money\",\n",
    "    \"everything\", \"fuck\", \"ll\", \"care\", \"lol\", \"go\", \"mostly\",\n",
    "    \"idk\", \"re\", \"option\", \"style\", \"pl\", \"full\", \"need\",\n",
    "    \"want\", \"guy\", \"subtle\", \"sweet\", \"one\", \"quality\",\n",
    "    \"main\", \"back\", \"buying\", \"different\", \"e\", \"probably\",\n",
    "    \"might\", \"form\", \"already\", \"specifically\", \"let\",\n",
    "    \"basically\", \"bad\", \"see\", \"work\", \"broke\", \"ones\",\n",
    "    \"happen\", \"say\", \"getting\", \"piece\", \"thank\", \"guess\",\n",
    "    \"doesn\", \"use\", \"exist\", \"including\", \"s\", \"possible\",\n",
    "    \"making\", \"definitely\", \"least\", \"h\", \"t\", \"year\", \"isn\",\n",
    "    \"hs\"\n",
    "])\n",
    "\n",
    "# Create the WordCloud object.\n",
    "wc = WordCloud(\n",
    "    width=1500,\n",
    "    height=800,\n",
    "    background_color=\"white\",   # Use a light background.\n",
    "    stopwords=custom_stopwords,\n",
    "    colormap=\"viridis\",\n",
    "    font_path=\"fontstuck-extended.ttf\",\n",
    "    collocations=False  # Avoid combining words based on co-occurrence.\n",
    ").generate(aggregated_text)\n",
    "\n",
    "# Plot the word cloud.\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(\"graphs/merch_wordcloud_unique.png\", format=\"png\", dpi=300, transparent=True)\n",
    "plt.show()\n"
   ],
   "id": "901d7b3ff0c888f0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
